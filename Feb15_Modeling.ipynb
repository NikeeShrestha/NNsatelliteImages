{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d42984b8-43d1-4d3b-80d2-565ac711c455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split,GroupShuffleSplit\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    GradientBoostingRegressor)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    RepeatedKFold,\n",
    "    RandomizedSearchCV,\n",
    "    KFold,\n",
    "    train_test_split,\n",
    "    GridSearchCV,\n",
    "    GroupKFold)\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from math import sqrt\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Suppress ConstantInputWarning\n",
    "warnings.filterwarnings(\"ignore\", category=stats.ConstantInputWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aee4f5b-8613-47f1-80b0-d3ac66825e1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class base:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.features = kwargs[\"features\"]\n",
    "        self.response = kwargs[\"response\"]\n",
    "\n",
    "    def preProcess_features(self, **kwargs):\n",
    "        if kwargs[\"rescale_type\"] == \"norm\":\n",
    "            standardized = preprocessing.StandardScaler()\n",
    "            features_processed = standardized.fit_transform(np.array(self.features))\n",
    "        elif kwargs[\"rescale_type\"] == \"minmax\":\n",
    "            norm = preprocessing.MinMaxScaler()\n",
    "            features_processed = norm.fit_transform(np.array(self.features))\n",
    "        else:\n",
    "            print(str(kwargs[\"rescale_type\"])+ \"rescaling technique not implemented \\n Defaulting to standardized variables\")\n",
    "            standardized = preprocessing.StandardScaler()\n",
    "            features_processed = standardized.fit_transform(np.array(self.features))\n",
    "\n",
    "        self.features_processed = features_processed\n",
    "        return features_processed\n",
    "\n",
    "    def predict(self, **kwargs):\n",
    "        features_to_predict = kwargs[\"features\"]\n",
    "        self.predictions = self.model.predict(features_to_predict)\n",
    "\n",
    "    def run_CVs(self, **kwargs):\n",
    "\n",
    "        standardized = preprocessing.StandardScaler()\n",
    "        norm = preprocessing.MinMaxScaler()\n",
    "\n",
    "        x_data = kwargs[\"features\"]\n",
    "        rescale_type = kwargs['rescale_type']\n",
    "\n",
    "        # Normalise or standardize, two different forms of rescaling\n",
    "        if kwargs[\"rescale_type\"] == \"norm\":\n",
    "            x_data = standardized.fit_transform(np.array(x_data))\n",
    "        elif kwargs[\"rescale_type\"] == \"minmax\":\n",
    "            x_data = norm.fit_transform(np.array(x_data))\n",
    "        else:\n",
    "            print(\"rescaling technique not implemented \\n Defaulting to standardized variables\")\n",
    "            x_data = standardized.fit_transform(np.array(x_data))\n",
    "\n",
    "        y_data = np.array(kwargs[\"response\"])\n",
    "        n_folds = kwargs[\"n_folds\"]\n",
    "        title = kwargs[\"title\"]\n",
    "\n",
    "        kf = KFold(n_splits=n_folds)\n",
    "        df = {}\n",
    "        fold_indices = {}\n",
    "\n",
    "        count = 1\n",
    "        for train_index, test_index in kf.split(x_data):\n",
    "            X_train, X_test = x_data[train_index], x_data[test_index]\n",
    "            y_train, y_test = y_data[train_index], y_data[test_index]\n",
    "\n",
    "            model_cv = kwargs[\"model_type\"]\n",
    "            model_cv.fit(X_train, y_train)\n",
    "\n",
    "            fold = model_cv.predict(X_test)\n",
    "            df[f\"Pred{count}\"] = fold\n",
    "            df[f\"Obs{count}\"] = y_test\n",
    "\n",
    "            fold_indices[f\"Train{count}\"] = train_index\n",
    "            fold_indices[f\"Test{count}\"] = test_index\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "        count = 1\n",
    "\n",
    "        comb_cv_obs = []\n",
    "        comb_cv_preds = []\n",
    "\n",
    "        # Wether or not to visualise the cross validation\n",
    "        try:\n",
    "            visualize = kwargs[\"visualize\"]\n",
    "        except:\n",
    "            visualize = None\n",
    "\n",
    "        if visualize:\n",
    "            for i in range(n_folds):\n",
    "                print(i)\n",
    "                print(f\"23{count}\")\n",
    "                ax = fig.add_subplot(int(n_folds/2),2,count)\n",
    "                sns.regplot(x=df[f\"Obs{count}\"], y=df[f\"Pred{count}\"])\n",
    "                ax.spines[\"right\"].set_visible(False)\n",
    "                ax.spines[\"top\"].set_visible(False)\n",
    "                ax.set_ylabel(\"Predicted\")\n",
    "                ax.set_xlabel(\"Observed\")\n",
    "                ax.set_title(f\"Fold{count}\")\n",
    "                r_val, pval = spearmanr(df[f\"Obs{count}\"], df[f\"Pred{count}\"])\n",
    "                r2_val = round(r_val ** 2, 2)\n",
    "                x_cord, y_cord = max(df[f\"Obs{count}\"]) * 0.15, max(df[f\"Pred{count}\"])\n",
    "                ax.annotate(f\"$R^2 = {r2_val}$\", (x_cord, y_cord))\n",
    "\n",
    "                comb_cv_preds.extend(df[f\"Pred{count}\"])\n",
    "                comb_cv_obs.extend(df[f\"Obs{count}\"])\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            R, pVal = spearmanr(comb_cv_obs, comb_cv_preds)\n",
    "            R2 = round(R ** 2, 2)\n",
    "\n",
    "            fig.suptitle(f\"{title} (Combined data $R^2$ = {R2})\")\n",
    "            plt.tight_layout()\n",
    "            direc = os.getcwd()\n",
    "            out_direc = f\"{direc}\"\n",
    "            os.makedirs(out_direc, exist_ok=True)\n",
    "            # plt.savefig(f'{out_direc}/Fold_{title}.png')\n",
    "            # plt.savefig(f'{out_direc}/Fold_{title}.svg')\n",
    "            # plt.show()\n",
    "\n",
    "            fig2 = plt.figure(figsize=(12, 10))\n",
    "            ax2 = fig2.add_subplot(111)\n",
    "            sns.regplot(x=comb_cv_obs, y=comb_cv_preds, ax=ax2)\n",
    "            ax2.spines[\"top\"].set_visible(False)\n",
    "            ax2.spines[\"right\"].set_visible(False)\n",
    "            ax2.set_title(title, pad=10)\n",
    "            r, pval = spearmanr(comb_cv_obs, comb_cv_preds)\n",
    "            r2 = round(r ** 2, 2)\n",
    "            x_coord = max(comb_cv_obs) * 0.75\n",
    "            y_coord = max(comb_cv_preds) * 0.99\n",
    "            ax2.text(x_coord, y_coord, f\"$R^2 = {round(r2,2)}$\")\n",
    "            ax2.set_xlabel(\"Observations\", labelpad=20)\n",
    "            ax2.set_ylabel(\"Predictions\", labelpad=20)\n",
    "            fig2.tight_layout()\n",
    "            fig2.savefig(f'{out_direc}/{title}.png') \n",
    "            # fig2.savefig(f'{out_direc}/{title}.svg')\n",
    "\n",
    "        return df, fold_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85f82666-d1dd-493e-a013-fea91119c666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LR(base):\n",
    "\n",
    "    \"\"\" Linear Regression Model \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features_processed = self.preProcess_features(rescale_type=kwargs.get(\"rescale_type\"))\n",
    "\n",
    "    def train_lr(self, **kwargs):\n",
    "        model = LinearRegression()\n",
    "\n",
    "        model.fit(self.features_processed, self.response)\n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    def run_CVs(self, **kwargs):\n",
    "        df, fold_indices = super().run_CVs(\n",
    "            model_type=LinearRegression(),\n",
    "            features=kwargs[\"features\"],\n",
    "            response=kwargs[\"response\"],\n",
    "            n_folds=kwargs[\"n_folds\"],\n",
    "            title=kwargs[\"title\"],\n",
    "            visualize=kwargs[\"visualize\"],\n",
    "            rescale_type=kwargs[\"rescale_type\"])\n",
    "\n",
    "        return df, fold_indices\n",
    "\n",
    "\n",
    "class RF(base):\n",
    "\n",
    "    \"\"\"\" Random Forest Regression Model \"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features_processed = self.preProcess_features(rescale_type=kwargs.get(\"rescale_type\"))\n",
    "\n",
    "\n",
    "    def grid_search(self, **kwargs):\n",
    "        n_estimators = [int(x) for x in np.linspace(start=100, stop=1000, num=10)]\n",
    "        max_features = [1, 2, 3, 4,5,6,7,8,9,10]\n",
    "        max_depth = [int(x) for x in np.linspace(10, stop=100, num=11)]\n",
    "        max_depth.append(None)\n",
    "        min_samples_split = [2, 5, 10]\n",
    "        min_samples_leaf = [10, 15, 20]\n",
    "        bootstrap = [True, False]\n",
    "        random_grid = {\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_features\": max_features,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"min_samples_split\": min_samples_split,\n",
    "            \"min_samples_leaf\": min_samples_leaf,\n",
    "            \"bootstrap\": bootstrap}\n",
    "       \n",
    "        rf = RandomForestRegressor()\n",
    "       \n",
    "        rf_random = RandomizedSearchCV(\n",
    "            estimator=rf,\n",
    "            param_distributions=random_grid,\n",
    "            n_iter=100,\n",
    "            cv=3,\n",
    "            verbose=0,\n",
    "            random_state=42,\n",
    "            n_jobs=-1)\n",
    "        rf_random.fit(self.features_processed, self.response)\n",
    "        # print(rf_random.best_params_)\n",
    "\n",
    "        self.ran_params = rf_random.best_params_\n",
    "\n",
    "    def train_rf(self, **kwargs):\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=self.ran_params[\"n_estimators\"],\n",
    "            min_samples_leaf=self.ran_params[\"min_samples_leaf\"],\n",
    "            min_samples_split=self.ran_params[\"min_samples_split\"],\n",
    "            max_features=self.ran_params[\"max_features\"],\n",
    "            max_depth=self.ran_params[\"max_depth\"],\n",
    "            bootstrap=self.ran_params[\"bootstrap\"])\n",
    "\n",
    "        model.fit(self.features_processed, self.response)\n",
    "        self.model = model\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def run_CVs(self, **kwargs):\n",
    "        df, fold_indices = super().run_CVs(\n",
    "            model_type=RandomForestRegressor(\n",
    "                n_estimators=self.ran_params[\"n_estimators\"],\n",
    "                min_samples_leaf=self.ran_params[\"min_samples_leaf\"],\n",
    "                min_samples_split=self.ran_params[\"min_samples_split\"],\n",
    "                max_features=self.ran_params[\"max_features\"],\n",
    "                max_depth=self.ran_params[\"max_depth\"],\n",
    "                bootstrap=self.ran_params[\"bootstrap\"]),\n",
    "            features=kwargs[\"features\"],\n",
    "            response=kwargs[\"response\"],\n",
    "            n_folds=kwargs[\"n_folds\"],\n",
    "            title=kwargs[\"title\"],\n",
    "            visualize=kwargs[\"visualize\"],\n",
    "            rescale_type=kwargs[\"rescale_type\"])\n",
    "\n",
    "        return df, fold_indices\n",
    "\n",
    "    def feature_importance(self, **kwargs):\n",
    "\n",
    "        importances = self.model.feature_importances_\n",
    "        self.feature_importance_std = np.std([tree.feature_importances_ for tree in self.model.estimators_], axis=0)\n",
    "        return importances\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class GB(base):\n",
    "\n",
    "    \"\"\" Gradient Boosting Regression Model \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features_processed = self.preProcess_features(rescale_type=kwargs.get(\"rescale_type\"))\n",
    "\n",
    "    def grid_search(self, **kwargs):\n",
    "\n",
    "        n_estimators = [int(x) for x in np.linspace(start=100, stop=1000, num=10)]\n",
    "        max_features = [1,2,3,4,5,6,7,8,9,10]\n",
    "        max_depth = [int(x) for x in np.linspace(10, stop=100, num=11)]\n",
    "        max_depth.append(None)\n",
    "        min_samples_split = [2, 5, 10]\n",
    "        min_samples_leaf = [10, 15, 20]\n",
    "        bootstrap = [True, False]  \n",
    "        random_grid = {\n",
    "            \"n_estimators\": n_estimators,\n",
    "            \"max_features\": max_features,\n",
    "            \"max_depth\": max_depth,\n",
    "            \"min_samples_split\": min_samples_split,\n",
    "            \"min_samples_leaf\": min_samples_leaf}\n",
    "\n",
    "        gb = GradientBoostingRegressor()\n",
    "        \n",
    "        gb_random = RandomizedSearchCV(\n",
    "            estimator=gb,\n",
    "            param_distributions=random_grid,\n",
    "            n_iter=100,\n",
    "            cv=3,\n",
    "            verbose=0,\n",
    "            random_state=42,\n",
    "            n_jobs=-1)  \n",
    "        gb_random.fit(self.features_processed, self.response)\n",
    "\n",
    "        self.ran_params = gb_random.best_params_\n",
    "\n",
    "    def train_gb(self, **kwargs):\n",
    "        # self.grid_search()\n",
    "        model = GradientBoostingRegressor(\n",
    "            n_estimators=self.ran_params[\"n_estimators\"],\n",
    "            min_samples_leaf=self.ran_params[\"min_samples_leaf\"],\n",
    "            min_samples_split=self.ran_params[\"min_samples_split\"],\n",
    "            max_features=self.ran_params[\"max_features\"],\n",
    "            max_depth=self.ran_params[\"max_depth\"])\n",
    "\n",
    "        model.fit(self.features_processed, self.response)\n",
    "        self.model = model\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def run_CVs(self, **kwargs):\n",
    "        df, fold_indices = super().run_CVs(\n",
    "            model_type=GradientBoostingRegressor(\n",
    "                n_estimators=self.ran_params[\"n_estimators\"],\n",
    "                min_samples_leaf=self.ran_params[\"min_samples_leaf\"],\n",
    "                min_samples_split=self.ran_params[\"min_samples_split\"],\n",
    "                max_features=self.ran_params[\"max_features\"],\n",
    "                max_depth=self.ran_params[\"max_depth\"]),\n",
    "            features=kwargs[\"features\"],\n",
    "            response=kwargs[\"response\"],\n",
    "            n_folds=kwargs[\"n_folds\"],\n",
    "            title=kwargs[\"title\"],\n",
    "            visualize=kwargs[\"visualize\"],\n",
    "            rescale_type=kwargs[\"rescale_type\"])\n",
    "\n",
    "        return df, fold_indices\n",
    "\n",
    "\n",
    "class PLSR(base):\n",
    "\n",
    "    \"\"\" Partial Least Squares Regression Model \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features_processed = self.preProcess_features(rescale_type=kwargs.get(\"rescale_type\"))\n",
    "\n",
    "    def optimum_ncomps(self, **kwargs):\n",
    "        self.features = np.array(self.features)\n",
    "        self.response = np.array(self.response)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.features,\n",
    "            self.response,\n",
    "            test_size=kwargs[\"test_size\"],\n",
    "            random_state=8675309)\n",
    "        # Compute the validation error for each n_comp\n",
    "        trait_plot = []\n",
    "        for n_comp in range(1, self.features.shape[1]):\n",
    "            # print(len(self.features))\n",
    "            my_plsr = PLSRegression(n_components=n_comp, scale=True)\n",
    "            my_plsr.fit(X_train, y_train)\n",
    "            preds = my_plsr.predict(X_test)\n",
    "            trait_rmse = sqrt(mean_squared_error(y_test, preds))\n",
    "            trait_plot.append(trait_rmse)\n",
    "\n",
    "        min_trait_index = trait_plot.index(min(trait_plot))\n",
    "\n",
    "        self.min_rmse = min(trait_plot)\n",
    "        self.ncomps_min_rsme = min_trait_index + 1\n",
    "\n",
    "    def train_plsr(self):\n",
    "        model = PLSRegression(n_components=self.ncomps_min_rsme, scale=True)\n",
    "        model.fit(self.features_processed, self.response)\n",
    "        self.model = model\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def run_CVs(self, **kwargs):\n",
    "        df, fold_indices = super().run_CVs(\n",
    "            model_type=PLSRegression(n_components=self.ncomps_min_rsme),\n",
    "            features=kwargs[\"features\"],\n",
    "            response=kwargs[\"response\"],\n",
    "            n_folds=kwargs[\"n_folds\"],\n",
    "            title=kwargs[\"title\"],\n",
    "            visualize=kwargs[\"visualize\"],\n",
    "            rescale_type=kwargs[\"rescale_type\"])\n",
    "        return df, fold_indices\n",
    "\n",
    "\n",
    "class SVM(base):\n",
    "\n",
    "    \"\"\" Support Vector Regression \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.features_processed = self.preProcess_features(rescale_type=kwargs.get(\"rescale_type\"))\n",
    "\n",
    "    def train_svm(self):\n",
    "        model = SVR(epsilon=2)\n",
    "        model.fit(self.features_processed, self.response)\n",
    "        self.model = model\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def run_CVs(self, **kwargs):\n",
    "        df, fold_indices = super().run_CVs(\n",
    "            model_type=SVR(epsilon=2),\n",
    "            features=kwargs[\"features\"],\n",
    "            response=kwargs[\"response\"],\n",
    "            n_folds=kwargs[\"n_folds\"],\n",
    "            title=kwargs[\"title\"],\n",
    "            visualize=kwargs[\"visualize\"],\n",
    "            rescale_type=kwargs[\"rescale_type\"])\n",
    "        return df, fold_indices\n",
    "\n",
    "    # Lasso\n",
    "    \n",
    "class Ridgemodel(base):\n",
    "    \n",
    "    \"\"\" lasso regression \"\"\"\n",
    "    \n",
    "    def __init__(self, features, response, **kwargs):\n",
    "        super().__init__(features=features, response=response, **kwargs)\n",
    "        self.features_processed = self.preProcess_features(rescale_type=kwargs.get(\"rescale_type\"))\n",
    "    \n",
    "    def paramSearch(self, **kwargs):\n",
    "        self.features = np.array(self.features)\n",
    "        self.response = np.array(self.response)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.features,\n",
    "            self.response,\n",
    "            test_size=kwargs[\"test_size\"],\n",
    "            random_state=8675309)\n",
    "        \n",
    "        ridge=Ridge()\n",
    "        \n",
    "        alphas = np.logspace(-3, 2, 100) \n",
    "        param_grid = {'alpha':alphas}\n",
    "        \n",
    "        grid_search = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        self.best_alpha = grid_search.best_params_['alpha']\n",
    "        \n",
    "    def train_ridge(self, **kwargs):\n",
    "        model=Ridge(alpha=self.best_alpha)\n",
    "        model.fit(self.features_processed, self.response)\n",
    "        self.model=model\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    # def predict(self, **)\n",
    "        \n",
    "        \n",
    "    def run_CVs(self,**kwargs):\n",
    "        df, fold_indices = super().run_CVs(\n",
    "            model_type=Ridge(alpha=self.best_alpha),\n",
    "            features=kwargs[\"features\"],\n",
    "            response=kwargs[\"response\"],\n",
    "            n_folds=kwargs[\"n_folds\"],\n",
    "            title=kwargs[\"title\"],\n",
    "            visualize=kwargs[\"visualize\"],\n",
    "            rescale_type=kwargs[\"rescale_type\"])\n",
    "        return df, fold_indices\n",
    "\n",
    "class Lassomodel(base):\n",
    "    \n",
    "    \"\"\" lasso regression \"\"\"\n",
    "    \n",
    "    def __init__(self, features, response, **kwargs):\n",
    "        super().__init__(features=features, response=response, **kwargs)\n",
    "        self.features_processed = self.preProcess_features(rescale_type=kwargs.get(\"rescale_type\"))\n",
    "    \n",
    "    def paramSearch(self, **kwargs):\n",
    "        self.features = np.array(self.features)\n",
    "        self.response = np.array(self.response)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            self.features,\n",
    "            self.response,\n",
    "            test_size=kwargs[\"test_size\"],\n",
    "            random_state=8675309)\n",
    "        \n",
    "        ridge=Lasso()\n",
    "        \n",
    "        alphas = np.logspace(-3, 4, 1000)\n",
    "        # print(alphas)\n",
    "        param_grid = {'alpha':alphas}\n",
    "        \n",
    "        grid_search = GridSearchCV(ridge, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        self.best_alpha = grid_search.best_params_['alpha']\n",
    "        \n",
    "    def train_lasso(self, **kwargs):\n",
    "        model=Lasso(alpha=self.best_alpha,max_iter=1000000)\n",
    "        model.fit(self.features_processed, self.response)\n",
    "        self.model=model\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def run_CVs(self,**kwargs):\n",
    "        df, fold_indices = super().run_CVs(\n",
    "            model_type=Lasso(alpha=self.best_alpha,max_iter=100000),\n",
    "            features=kwargs[\"features\"],\n",
    "            response=kwargs[\"response\"],\n",
    "            n_folds=kwargs[\"n_folds\"],\n",
    "            title=kwargs[\"title\"],\n",
    "            visualize=kwargs[\"visualize\"],\n",
    "            rescale_type=kwargs[\"rescale_type\"])\n",
    "        return df, fold_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a54a2ff2-ea62-4bde-868f-687b6d8f793b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path='/home/schnablelab/Documents/NNSatelliteImages/Data/'\n",
    "# mainfolder=os.listdir(path)\n",
    "# Correlation=[]\n",
    "# for mainfolders in mainfolder:\n",
    "#     if not mainfolders.endswith('.csv'):\n",
    "#         mainfolderspath=os.path.join(path,mainfolders)\n",
    "#         location=os.path.basename(mainfolderspath)\n",
    "#         print(location)\n",
    "        \n",
    "#         subfolder=os.listdir(mainfolderspath)\n",
    "#         for subfolders in subfolder:\n",
    "            \n",
    "#             if subfolders=='Satelliteimages':\n",
    "#                 # continue\n",
    "                \n",
    "#                 satfolderpath=os.path.join(mainfolderspath,subfolders)\n",
    "                \n",
    "#                 satsubfolders=os.listdir(satfolderpath)\n",
    "#                 bands='Satellite Image'\n",
    "                \n",
    "#                 for satsubfolder in satsubfolders:\n",
    "                    \n",
    "#                     if satsubfolder=='sixband':\n",
    "                        \n",
    "                    \n",
    "#                         finalsatfolderpath=os.path.join(satfolderpath,satsubfolder)\n",
    "                    \n",
    "#                         satfiles=os.listdir(finalsatfolderpath)\n",
    "                        \n",
    "#                         for file in satfiles:\n",
    "#                             if file.endswith('_genotype.csv'):\n",
    "                                \n",
    "#                                 timepoint=file.split('_')[-2]\n",
    "                                \n",
    "#                                 print(timepoint)\n",
    "                                \n",
    "#                                 datafilepath=os.path.join(finalsatfolderpath,file)\n",
    "                                \n",
    "#                                 datadf=pd.read_csv(datafilepath,index_col=0)\n",
    "                                \n",
    "#                                 datadf=datadf.iloc[:,list(range(0, 39))+[44]+[-1]]\n",
    "#                                 # print(datadf.columns)\n",
    "                                \n",
    "#                                 datadf=datadf.dropna(subset=['yieldPerAcre','genotype'])\n",
    "                                \n",
    "#                                 train_inds, test_inds = next(GroupShuffleSplit(test_size=.3, n_splits=2, random_state = 7).split(datadf, groups=datadf['genotype']))\n",
    "\n",
    "#                                 train = datadf.iloc[train_inds]\n",
    "                                \n",
    "#                                 test = datadf.iloc[test_inds]\n",
    "                                \n",
    "#                                 features=train[train.columns[train.columns.str.contains('mean|sum|median')]]\n",
    "#                                 response=train['yieldPerAcre']\n",
    "                                \n",
    "                                \n",
    "#                                 testfeatures=test[test.columns[train.columns.str.contains('mean|sum|median')]]\n",
    "#                                 testresponse=test['yieldPerAcre']\n",
    "#                                 Preprocessing=preprocessing.StandardScaler()\n",
    "#                                 testfeatures=Preprocessing.fit_transform(testfeatures)\n",
    "                                \n",
    "                                \n",
    "#                                 ##########RandomForest###################\n",
    "                                \n",
    "#                                 model=RF(response=response,features=features,rescale_type=\"norm\")\n",
    "#                                 model.grid_search()\n",
    "#                                 RFmodel=model.train_rf(response=response, features=features)\n",
    "                                \n",
    "#                                 results=RFmodel.predict(testfeatures)\n",
    "#                                 results = results.flatten()\n",
    "#                                 r,p=pearsonr(results,testresponse)\n",
    "#                                 model='RF'\n",
    "#                                 r_squared=r*r\n",
    "#                                 print(model)\n",
    "#                                 print(r_squared)\n",
    "                                \n",
    "                                \n",
    "#                                 Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "                                \n",
    "#                                 #############PLSR##############\n",
    "#                                 plsrmodel=PLSR(response=response, features=features,rescale_type=\"norm\")\n",
    "#                                 plsrmodel.optimum_ncomps(test_size=0.1)\n",
    "#                                 plsrmodel1=plsrmodel.train_plsr()\n",
    "                                \n",
    "#                                 # Preprocessing=preprocessing.StandardScaler()\n",
    "#                                 # testfeatures=Preprocessing.fit_transform(testfeatures)\n",
    "#                                 results=plsrmodel1.predict(testfeatures)\n",
    "#                                 results = results.flatten()\n",
    "#                                 # print(len(results), len(testresponse))\n",
    "                \n",
    "#                                 r,p=pearsonr(results,testresponse)\n",
    "#                                 model='PSLR'\n",
    "#                                 r_squared=r*r\n",
    "#                                 print(model)\n",
    "                    \n",
    "#                                 print(r*r)\n",
    "#                                 Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "                        \n",
    "#                                 ############################LR######################\n",
    "#                                 lrmodel=LR(response=response, features=features,rescale_type=\"norm\")\n",
    "\n",
    "#                                 lrmodel1=lrmodel.train_lr(response=response, features=features)\n",
    "                                \n",
    "#                                 results=lrmodel1.predict(testfeatures)\n",
    "#                                 results=results.flatten()\n",
    "                                \n",
    "#                                 r,p=pearsonr(results,testresponse)\n",
    "#                                 r_squared=r*r\n",
    "#                                 model='LR'\n",
    "#                                 print('lr')\n",
    "#                                 print(r_squared)\n",
    "#                                 Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "                                \n",
    "#                                 ################Ridge###################\n",
    "                                \n",
    "# #                                 ridgemodel=Ridgemodel(response=response, features=features,rescale_type=\"norm\")\n",
    "# #                                 ridgemodel.paramSearch(test_size=0.1)\n",
    "# #                                 ridgemodel1=ridgemodel.train_ridge(response=response, features=features)\n",
    "                                \n",
    "# #                                 results=ridgemodel1.predict(testfeatures)\n",
    "# #                                 results=results.flatten()\n",
    "                                \n",
    "# #                                 r,p=pearsonr(results,testresponse)\n",
    "# #                                 print(r*r)\n",
    "                                \n",
    "#                                 ##################Lasso##################\n",
    "#                                 lassomodel=Lassomodel(response=response, features=features,rescale_type=\"norm\")\n",
    "#                                 lassomodel.paramSearch(test_size=0.1)\n",
    "#                                 lassomodel1=lassomodel.train_lasso()\n",
    "                                \n",
    "#                                 results=lassomodel1.predict(testfeatures)\n",
    "#                                 results=results.flatten()\n",
    "                                \n",
    "#                                 r,p=pearsonr(results,testresponse)\n",
    "#                                 r_squared=r*r\n",
    "#                                 model='LASSO'\n",
    "#                                 print(model)\n",
    "#                                 print(r*r)\n",
    "#                                 Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "                                \n",
    "#                                 ############SVM############\n",
    "#                                 svmmodel=SVM(response=response, features=features,rescale_type=\"norm\")\n",
    "#                                 svmmodel1=svmmodel.train_svm()\n",
    "                                \n",
    "#                                 results=svmmodel1.predict(testfeatures)\n",
    "#                                 results=results.flatten()\n",
    "                                \n",
    "#                                 r,p=pearsonr(results,testresponse)\n",
    "#                                 r_squared=r*r\n",
    "#                                 model='SVM'\n",
    "#                                 print('svm')\n",
    "#                                 print(r*r)\n",
    "#                                 Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "                                \n",
    "#                                 ######GB#################\n",
    "                                \n",
    "#                                 gbmodel=GB(response=response, features=features,rescale_type=\"norm\")\n",
    "#                                 gbmodel.grid_search()\n",
    "#                                 gbmodel1=gbmodel.train_gb(response=response, features=features)\n",
    "                                \n",
    "#                                 results=gbmodel1.predict(testfeatures)\n",
    "#                                 results=results.flatten()\n",
    "                                \n",
    "#                                 r,p=pearsonr(results,testresponse)\n",
    "#                                 r_squared=r*r\n",
    "#                                 model='GB'\n",
    "                                \n",
    "#                                 print(r*r)\n",
    "#                                 Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "                                \n",
    "#             if subfolders=='UAV':\n",
    "                \n",
    "#                 uavfolderpath=os.path.join(mainfolderspath,subfolders)\n",
    "                \n",
    "#                 uavfiles=os.listdir(uavfolderpath)\n",
    "#                 bands='UAV'\n",
    "\n",
    "#                 for file in uavfiles:\n",
    "#                     if file.endswith('_genotype.csv'):\n",
    "#                         print(file)\n",
    "\n",
    "#                         timepoint=file.split('_')[-2]\n",
    "\n",
    "#                         print(timepoint)\n",
    "\n",
    "#                         datafilepath=os.path.join(uavfolderpath,file)\n",
    "\n",
    "#                         uavdf=pd.read_csv(datafilepath,index_col=0)\n",
    "\n",
    "#                         uavdf=uavdf.iloc[:,list(range(0, 18))+[23]+[-1]]\n",
    "#                         uavdf=uavdf.dropna(subset=['yieldPerAcre','genotype'])\n",
    "\n",
    "#                         # datadf=datadf.dropna(subset=['yieldPerAcre','genotype'])\n",
    "\n",
    "#                         train_inds, test_inds = next(GroupShuffleSplit(test_size=.3, n_splits=2, random_state = 7).split(uavdf, groups=uavdf['genotype']))\n",
    "\n",
    "#                         train = uavdf.iloc[train_inds]\n",
    "\n",
    "#                         test = uavdf.iloc[test_inds]\n",
    "\n",
    "#                         features=train[train.columns[train.columns.str.contains('mean|sum|median')]]\n",
    "#                         response=train['yieldPerAcre']\n",
    "\n",
    "\n",
    "#                         testfeatures=test[test.columns[train.columns.str.contains('mean|sum|median')]]\n",
    "#                         testresponse=test['yieldPerAcre']\n",
    "#                         Preprocessing=preprocessing.StandardScaler()\n",
    "#                         testfeatures=Preprocessing.fit_transform(testfeatures)\n",
    "\n",
    "\n",
    "#                         ##########RandomForest###################\n",
    "\n",
    "#                         model=RF(response=response,features=features,rescale_type=\"norm\")\n",
    "#                         model.grid_search()\n",
    "#                         RFmodel=model.train_rf(response=response, features=features)\n",
    "\n",
    "#                         results=RFmodel.predict(testfeatures)\n",
    "#                         results = results.flatten()\n",
    "#                         r,p=pearsonr(results,testresponse)\n",
    "#                         model='RF'\n",
    "#                         r_squared=r*r\n",
    "#                         print('rf')\n",
    "#                         print(r_squared)\n",
    "                        \n",
    "#                         Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "\n",
    "#                         #############PLSR##############\n",
    "#                         plsrmodel=PLSR(response=response, features=features,rescale_type=\"norm\")\n",
    "#                         plsrmodel.optimum_ncomps(test_size=0.1)\n",
    "#                         plsrmodel1=plsrmodel.train_plsr()\n",
    "\n",
    "#                         # Preprocessing=preprocessing.StandardScaler()\n",
    "#                         # testfeatures=Preprocessing.fit_transform(testfeatures)\n",
    "#                         results=plsrmodel1.predict(testfeatures)\n",
    "#                         results = results.flatten()\n",
    "#                         # print(len(results), len(testresponse))\n",
    "\n",
    "#                         r,p=pearsonr(results,testresponse)\n",
    "#                         r_squared=r*r\n",
    "#                         model='PLSR'\n",
    "#                         print('plsrmodel')\n",
    "#                         print(r*r)\n",
    "#                         Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "\n",
    "#                         ############################LR######################\n",
    "#                         lrmodel=LR(response=response, features=features,rescale_type=\"norm\")\n",
    "\n",
    "#                         lrmodel1=lrmodel.train_lr(response=response, features=features)\n",
    "\n",
    "#                         results=lrmodel1.predict(testfeatures)\n",
    "#                         results=results.flatten()\n",
    "\n",
    "#                         r,p=pearsonr(results,testresponse)\n",
    "#                         r_squared=r*r\n",
    "#                         model='LR'\n",
    "#                         print('lr')\n",
    "#                         print(r*r)\n",
    "#                         Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "\n",
    "#                         ################Ridge###################\n",
    "\n",
    "# #                         ridgemodel=Ridgemodel(response=response, features=features,rescale_type=\"norm\")\n",
    "# #                         ridgemodel.paramSearch(test_size=0.1)\n",
    "# #                         ridgemodel1=ridgemodel.train_ridge(response=response, features=features)\n",
    "\n",
    "# #                         results=ridgemodel1.predict(testfeatures)\n",
    "# #                         results=results.flatten()\n",
    "\n",
    "# #                         r,p=pearsonr(results,testresponse)\n",
    "# #                         print('ridge')\n",
    "# #                         print(r*r)\n",
    "\n",
    "#                         ##################Lasso##################\n",
    "#                         lassomodel=Lassomodel(response=response, features=features,rescale_type=\"norm\")\n",
    "#                         lassomodel.paramSearch(test_size=0.1)\n",
    "#                         lassomodel1=lassomodel.train_lasso()\n",
    "\n",
    "#                         results=lassomodel1.predict(testfeatures)\n",
    "#                         results=results.flatten()\n",
    "\n",
    "#                         r,p=pearsonr(results,testresponse)\n",
    "#                         r_squared=r*r\n",
    "#                         model='LASSO'\n",
    "#                         print('lassomodel')\n",
    "#                         print(r*r)\n",
    "#                         Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "\n",
    "#                         ############SVM############\n",
    "#                         svmmodel=SVM(response=response, features=features,rescale_type=\"norm\")\n",
    "#                         svmmodel1=svmmodel.train_svm()\n",
    "\n",
    "#                         results=svmmodel1.predict(testfeatures)\n",
    "#                         results=results.flatten()\n",
    "\n",
    "#                         r,p=pearsonr(results,testresponse)\n",
    "#                         model='SVM'\n",
    "#                         r_squared=r*r\n",
    "#                         print('svm')\n",
    "#                         print(r*r)\n",
    "#                         Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "\n",
    "#                         ######GB#################\n",
    "\n",
    "#                         gbmodel=GB(response=response, features=features,rescale_type=\"norm\")\n",
    "#                         gbmodel.grid_search()\n",
    "#                         gbmodel1=gbmodel.train_gb(response=response, features=features)\n",
    "\n",
    "#                         results=gbmodel1.predict(testfeatures)\n",
    "#                         results=results.flatten()\n",
    "\n",
    "#                         r,p=pearsonr(results,testresponse)\n",
    "#                         r_squared=r*r\n",
    "#                         model='GB'\n",
    "#                         print('gb')\n",
    "#                         print(r*r)\n",
    "#                         Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared})\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca803ef2-33d9-4e3c-bc11-0f2af6b6edd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scottsbluff\n",
      "SatelliteImage_6bands_TP1_genotype.csv\n",
      "TP1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 98\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m##########RandomForest###################\u001b[39;00m\n\u001b[1;32m     97\u001b[0m model\u001b[38;5;241m=\u001b[39mRF(response\u001b[38;5;241m=\u001b[39mresponse,features\u001b[38;5;241m=\u001b[39mfeatures,rescale_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m model\u001b[38;5;241m.\u001b[39mgrid_search()\n\u001b[1;32m     99\u001b[0m RFmodel\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain_rf(response\u001b[38;5;241m=\u001b[39mresponse, features\u001b[38;5;241m=\u001b[39mfeatures)\n\u001b[1;32m    101\u001b[0m results\u001b[38;5;241m=\u001b[39mRFmodel\u001b[38;5;241m.\u001b[39mpredict(testfeatures)\n",
      "Cell \u001b[0;32mIn[3], line 63\u001b[0m, in \u001b[0;36mRF.grid_search\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor()\n\u001b[1;32m     55\u001b[0m rf_random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     56\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrf,\n\u001b[1;32m     57\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mrandom_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m,\n\u001b[1;32m     62\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m rf_random\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_processed, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# print(rf_random.best_params_)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mran_params \u001b[38;5;241m=\u001b[39m rf_random\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1806\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1806\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1807\u001b[0m         ParameterSampler(\n\u001b[1;32m   1808\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[1;32m   1809\u001b[0m         )\n\u001b[1;32m   1810\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path='/home/schnablelab/Documents/NNSatelliteImages/Data/'\n",
    "mainfolder=os.listdir(path)\n",
    "Correlation=[]\n",
    "for mainfolders in mainfolder:\n",
    "    if not mainfolders.endswith('.csv'):\n",
    "        mainfolderspath=os.path.join(path,mainfolders)\n",
    "        location=os.path.basename(mainfolderspath)\n",
    "        print(location)\n",
    "        # if not location=='Crawfordsville':\n",
    "        #     continue\n",
    "        \n",
    "        subfolder=os.listdir(mainfolderspath)\n",
    "        for subfolders in subfolder:\n",
    "            \n",
    "            if subfolders=='Satelliteimages':\n",
    "                # continue\n",
    "                \n",
    "                satfolderpath=os.path.join(mainfolderspath,subfolders)\n",
    "                \n",
    "                satsubfolders=os.listdir(satfolderpath)\n",
    "                bands='Satellite Image'\n",
    "                \n",
    "                for satsubfolder in satsubfolders:\n",
    "                    \n",
    "                    if satsubfolder=='sixband':\n",
    "                        \n",
    "                    \n",
    "                        finalsatfolderpath=os.path.join(satfolderpath,satsubfolder)\n",
    "                    \n",
    "                        satfiles=os.listdir(finalsatfolderpath)\n",
    "                        \n",
    "                        for file in satfiles:\n",
    "                            if file.endswith('_genotype.csv'):\n",
    "                                print(file)\n",
    "                                \n",
    "                                timepoint=file.split('_')[-2]\n",
    "                                \n",
    "                                print(timepoint)\n",
    "                                \n",
    "                                datafilepath=os.path.join(finalsatfolderpath,file)\n",
    "                                \n",
    "                                datadf=pd.read_csv(datafilepath,index_col=0)\n",
    "                                # print(datadf.columns)\n",
    "                                datadf=datadf.iloc[:,list(range(0, 39))+[45]+[-1]]\n",
    "                                \n",
    "                                \n",
    "                                datadf=datadf.dropna(subset=['yieldPerAcre','genotype'])\n",
    "#                                 print(datadf.shape)\n",
    "#                                 continue\n",
    "                                \n",
    "                                # train_inds, test_inds = next(GroupShuffleSplit(test_size=.2, n_splits=5, random_state = 7).split(datadf, groups=datadf['genotype']))\n",
    "                                # print(train_inds)\n",
    "                                group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "                                # Getting the indices for splitting\n",
    "                                splits = group_kfold.split(X=datadf, groups=datadf['genotype'])\n",
    "                                \n",
    "                                # for train, test in splits:\n",
    "                                #     print(train,test)\n",
    "\n",
    "                                \n",
    "#                                 unique_genotypes = datadf['genotype'].unique()\n",
    "\n",
    "#                                 # Shuffle the unique genotypes\n",
    "#                                 np.random.shuffle(unique_genotypes)\n",
    "\n",
    "#                                 # Partition the genotypes into five folds\n",
    "#                                 fold_indices = []\n",
    "#                                 fold_size = len(unique_genotypes) // 5\n",
    "#                                 for i in range(5):\n",
    "#                                     if i < 4:\n",
    "#                                         test_genotypes = unique_genotypes[i * fold_size: (i + 1) * fold_size]\n",
    "#                                     else:\n",
    "#                                         test_genotypes = unique_genotypes[i * fold_size:]\n",
    "\n",
    "#                                     test_index = datadf['genotype'].isin(test_genotypes)\n",
    "#                                     train_index = ~test_index\n",
    "\n",
    "#                                     fold_indices.append((np.where(train_index)[0], np.where(test_index)[0]))\n",
    "#                                                                 # train = datadf.iloc[train_inds]\n",
    "                                rep=1\n",
    "                                for trainindex, testindex in splits:\n",
    "                                    \n",
    "                                    train=datadf.iloc[trainindex]\n",
    "                                    test=datadf.iloc[testindex]\n",
    "                                    \n",
    "                                    features=train[train.columns[train.columns.str.contains('mean|sum|median')]]\n",
    "                                    response=train['yieldPerAcre']\n",
    "                                    \n",
    "                                    testfeatures=test[test.columns[train.columns.str.contains('mean|sum|median')]]\n",
    "                                    testresponse=test['yieldPerAcre']\n",
    "                                    Preprocessing=preprocessing.StandardScaler()\n",
    "                                    testfeatures=Preprocessing.fit_transform(testfeatures)\n",
    "                                    \n",
    "                                    ##########RandomForest###################\n",
    "                                    \n",
    "                                    model=RF(response=response,features=features,rescale_type=\"norm\")\n",
    "                                    model.grid_search()\n",
    "                                    RFmodel=model.train_rf(response=response, features=features)\n",
    "                                    \n",
    "                                    results=RFmodel.predict(testfeatures)\n",
    "                                    results = results.flatten()\n",
    "                                    r,p=pearsonr(results,testresponse)\n",
    "                                    model='RF'\n",
    "                                    r_squared=r*r\n",
    "                                    print(model,f'Fold:{rep}')\n",
    "                                    print(r_squared)\n",
    "                                    \n",
    "                                    Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared, 'rep':rep})\n",
    "\n",
    "                                    #############PLSR##############\n",
    "                                    plsrmodel=PLSR(response=response, features=features,rescale_type=\"norm\")\n",
    "                                    plsrmodel.optimum_ncomps(test_size=0.1)\n",
    "                                    plsrmodel1=plsrmodel.train_plsr()\n",
    "\n",
    "                                    # Preprocessing=preprocessing.StandardScaler()\n",
    "                                    # testfeatures=Preprocessing.fit_transform(testfeatures)\n",
    "                                    results=plsrmodel1.predict(testfeatures)\n",
    "                                    results = results.flatten()\n",
    "                                    # print(len(results), len(testresponse))\n",
    "\n",
    "                                    r,p=pearsonr(results,testresponse)\n",
    "                                    model='PSLR'\n",
    "                                    r_squared=r*r\n",
    "                                    print(model,f'Fold:{rep}')\n",
    "\n",
    "                                    print(r*r)\n",
    "                                    Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "                        \n",
    "                                    ############################LR######################\n",
    "                                    lrmodel=LR(response=response, features=features,rescale_type=\"norm\")\n",
    "\n",
    "                                    lrmodel1=lrmodel.train_lr(response=response, features=features)\n",
    "\n",
    "                                    results=lrmodel1.predict(testfeatures)\n",
    "                                    results=results.flatten()\n",
    "\n",
    "                                    r,p=pearsonr(results,testresponse)\n",
    "                                    r_squared=r*r\n",
    "                                    model='LR'\n",
    "                                    print(model,f'Fold:{rep}')\n",
    "                                    print(r_squared)\n",
    "                                    \n",
    "                                    Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "\n",
    "                                    ################Ridge###################\n",
    "\n",
    "    #                                 ridgemodel=Ridgemodel(response=response, features=features,rescale_type=\"norm\")\n",
    "    #                                 ridgemodel.paramSearch(test_size=0.1)\n",
    "    #                                 ridgemodel1=ridgemodel.train_ridge(response=response, features=features)\n",
    "\n",
    "    #                                 results=ridgemodel1.predict(testfeatures)\n",
    "    #                                 results=results.flatten()\n",
    "\n",
    "    #                                 r,p=pearsonr(results,testresponse)\n",
    "    #                                 print(r*r)\n",
    "\n",
    "                                    ##################Lasso##################\n",
    "                                    lassomodel=Lassomodel(response=response, features=features,rescale_type=\"norm\")\n",
    "                                    lassomodel.paramSearch(test_size=0.1)\n",
    "                                    lassomodel1=lassomodel.train_lasso()\n",
    "\n",
    "                                    results=lassomodel1.predict(testfeatures)\n",
    "                                    results=results.flatten()\n",
    "\n",
    "                                    r,p=pearsonr(results,testresponse)\n",
    "                                    r_squared=r*r\n",
    "                                    model='LASSO'\n",
    "                                    print(model,f'Fold:{rep}')\n",
    "                                    print(r*r)\n",
    "                                    Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "\n",
    "                                    ############SVM############\n",
    "                                    svmmodel=SVM(response=response, features=features,rescale_type=\"norm\")\n",
    "                                    svmmodel1=svmmodel.train_svm()\n",
    "\n",
    "                                    results=svmmodel1.predict(testfeatures)\n",
    "                                    results=results.flatten()\n",
    "\n",
    "                                    r,p=pearsonr(results,testresponse)\n",
    "                                    r_squared=r*r\n",
    "                                    model='SVM'\n",
    "                                    print(model,f'Fold:{rep}')\n",
    "                                    print(r*r)\n",
    "                                    Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "\n",
    "                                    ######GB#################\n",
    "\n",
    "                                    gbmodel=GB(response=response, features=features,rescale_type=\"norm\")\n",
    "                                    gbmodel.grid_search()\n",
    "                                    gbmodel1=gbmodel.train_gb(response=response, features=features)\n",
    "\n",
    "                                    results=gbmodel1.predict(testfeatures)\n",
    "                                    results=results.flatten()\n",
    "\n",
    "                                    r,p=pearsonr(results,testresponse)\n",
    "                                    r_squared=r*r\n",
    "                                    model='GB'\n",
    "                                    print(model,f'Fold:{rep}')\n",
    "                                    print(r*r)\n",
    "                                    Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "                                    \n",
    "                                    rep=rep+1\n",
    "                                \n",
    "            if subfolders=='UAV':\n",
    "                # continue\n",
    "                \n",
    "                uavfolderpath=os.path.join(mainfolderspath,subfolders)\n",
    "                \n",
    "                uavfiles=os.listdir(uavfolderpath)\n",
    "                bands='UAV'\n",
    "\n",
    "                for file in uavfiles:\n",
    "                    if file.endswith('_genotype.csv'):\n",
    "                        print(file)\n",
    "\n",
    "                        timepoint=file.split('_')[-2]\n",
    "\n",
    "                        print(timepoint)\n",
    "\n",
    "                        datafilepath=os.path.join(uavfolderpath,file)\n",
    "\n",
    "                        uavdf=pd.read_csv(datafilepath,index_col=0)\n",
    "\n",
    "                        uavdf=uavdf.iloc[:,list(range(0, 18))+[24]+[-1]]\n",
    "                        uavdf=uavdf.dropna(subset=['yieldPerAcre','genotype'])\n",
    "                        # print(uavdf.shape)\n",
    "                        # continue\n",
    "                        \n",
    "                    \n",
    "                        group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "                                # Getting the indices for splitting\n",
    "                        splits = group_kfold.split(X=uavdf, groups=uavdf['genotype'])\n",
    "                                \n",
    "                                # for train, test in splits:\n",
    "                                #     print(train,test)\n",
    "\n",
    "                                \n",
    "#                                 unique_genotypes = datadf['genotype'].unique()\n",
    "\n",
    "#                                 # Shuffle the unique genotypes\n",
    "#                                 np.random.shuffle(unique_genotypes)\n",
    "\n",
    "#                                 # Partition the genotypes into five folds\n",
    "#                                 fold_indices = []\n",
    "#                                 fold_size = len(unique_genotypes) // 5\n",
    "#                                 for i in range(5):\n",
    "#                                     if i < 4:\n",
    "#                                         test_genotypes = unique_genotypes[i * fold_size: (i + 1) * fold_size]\n",
    "#                                     else:\n",
    "#                                         test_genotypes = unique_genotypes[i * fold_size:]\n",
    "\n",
    "#                                     test_index = datadf['genotype'].isin(test_genotypes)\n",
    "#                                     train_index = ~test_index\n",
    "\n",
    "#                                     fold_indices.append((np.where(train_index)[0], np.where(test_index)[0]))\n",
    "#                                                                 # train = datadf.iloc[train_inds]\n",
    "                        rep=1\n",
    "                        # print(fold_indices)\n",
    "                        print(uavdf.shape)\n",
    "                        for trainindex, testindex in splits:\n",
    "                            # print(trainindex)\n",
    "                            max_value = trainindex.max()\n",
    "                            max_testvalue=testindex.max()\n",
    "                            \n",
    "#                             if location=='Crawfordsville' and max_value==486:\n",
    "#                                 trainindex = trainindex[trainindex != max_value]\n",
    "                                \n",
    "#                             if location=='Crawfordsville' and max_testvalue==486:\n",
    "#                                 testindex=testindex[testindex != max_testvalue]\n",
    "                            \n",
    "                            train=uavdf.iloc[trainindex]\n",
    "                            \n",
    "                            test=uavdf.iloc[testindex]\n",
    "\n",
    "\n",
    "#                             train = uavdf.iloc[train_inds]\n",
    "\n",
    "#                             test = uavdf.iloc[test_inds]\n",
    "\n",
    "                            features=train[train.columns[train.columns.str.contains('mean|sum|median')]]\n",
    "                            response=train['yieldPerAcre']\n",
    "\n",
    "\n",
    "                            testfeatures=test[test.columns[train.columns.str.contains('mean|sum|median')]]\n",
    "                            testresponse=test['yieldPerAcre']\n",
    "                            Preprocessing=preprocessing.StandardScaler()\n",
    "                            testfeatures=Preprocessing.fit_transform(testfeatures)\n",
    "\n",
    "\n",
    "                            ##########RandomForest###################\n",
    "\n",
    "                            model=RF(response=response,features=features,rescale_type=\"norm\")\n",
    "                            model.grid_search()\n",
    "                            RFmodel=model.train_rf(response=response, features=features)\n",
    "\n",
    "                            results=RFmodel.predict(testfeatures)\n",
    "                            results = results.flatten()\n",
    "                            r,p=pearsonr(results,testresponse)\n",
    "                            model='RF'\n",
    "                            r_squared=r*r\n",
    "                            print(model,f'Fold:{rep}')\n",
    "                            print(r_squared)\n",
    "\n",
    "                            Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "\n",
    "                            #############PLSR##############\n",
    "                            plsrmodel=PLSR(response=response, features=features,rescale_type=\"norm\")\n",
    "                            plsrmodel.optimum_ncomps(test_size=0.1)\n",
    "                            plsrmodel1=plsrmodel.train_plsr()\n",
    "\n",
    "                            # Preprocessing=preprocessing.StandardScaler()\n",
    "                            # testfeatures=Preprocessing.fit_transform(testfeatures)\n",
    "                            results=plsrmodel1.predict(testfeatures)\n",
    "                            results = results.flatten()\n",
    "                            # print(len(results), len(testresponse))\n",
    "\n",
    "                            r,p=pearsonr(results,testresponse)\n",
    "                            r_squared=r*r\n",
    "                            model='PLSR'\n",
    "                            print(model,f'Fold:{rep}')\n",
    "                            print(r*r)\n",
    "                            Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "\n",
    "                            ############################LR######################\n",
    "                            lrmodel=LR(response=response, features=features,rescale_type=\"norm\")\n",
    "\n",
    "                            lrmodel1=lrmodel.train_lr(response=response, features=features)\n",
    "\n",
    "                            results=lrmodel1.predict(testfeatures)\n",
    "                            results=results.flatten()\n",
    "\n",
    "                            r,p=pearsonr(results,testresponse)\n",
    "                            r_squared=r*r\n",
    "                            model='LR'\n",
    "                            print(model,f'Fold:{rep}')\n",
    "                            print(r*r)\n",
    "                            Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "\n",
    "                            ################Ridge###################\n",
    "\n",
    "    #                         ridgemodel=Ridgemodel(response=response, features=features,rescale_type=\"norm\")\n",
    "    #                         ridgemodel.paramSearch(test_size=0.1)\n",
    "    #                         ridgemodel1=ridgemodel.train_ridge(response=response, features=features)\n",
    "\n",
    "    #                         results=ridgemodel1.predict(testfeatures)\n",
    "    #                         results=results.flatten()\n",
    "\n",
    "    #                         r,p=pearsonr(results,testresponse)\n",
    "    #                         print('ridge')\n",
    "    #                         print(r*r)\n",
    "\n",
    "                            ##################Lasso##################\n",
    "                            lassomodel=Lassomodel(response=response, features=features,rescale_type=\"norm\")\n",
    "                            lassomodel.paramSearch(test_size=0.1)\n",
    "                            lassomodel1=lassomodel.train_lasso()\n",
    "\n",
    "                            results=lassomodel1.predict(testfeatures)\n",
    "                            results=results.flatten()\n",
    "\n",
    "                            r,p=pearsonr(results,testresponse)\n",
    "                            r_squared=r*r\n",
    "                            model='LASSO'\n",
    "                            print(model,f'Fold:{rep}')\n",
    "                            print(r*r)\n",
    "                            Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "\n",
    "                            ############SVM############\n",
    "                            svmmodel=SVM(response=response, features=features,rescale_type=\"norm\")\n",
    "                            svmmodel1=svmmodel.train_svm()\n",
    "\n",
    "                            results=svmmodel1.predict(testfeatures)\n",
    "                            results=results.flatten()\n",
    "\n",
    "                            r,p=pearsonr(results,testresponse)\n",
    "                            model='SVM'\n",
    "                            r_squared=r*r\n",
    "                            print(model,f'Fold:{rep}')\n",
    "                            print(r*r)\n",
    "                            Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "\n",
    "                            ######GB#################\n",
    "\n",
    "                            gbmodel=GB(response=response, features=features,rescale_type=\"norm\")\n",
    "                            gbmodel.grid_search()\n",
    "                            gbmodel1=gbmodel.train_gb(response=response, features=features)\n",
    "\n",
    "                            results=gbmodel1.predict(testfeatures)\n",
    "                            results=results.flatten()\n",
    "\n",
    "                            r,p=pearsonr(results,testresponse)\n",
    "                            r_squared=r*r\n",
    "                            model='GB'\n",
    "                            print(model,f'Fold:{rep}')\n",
    "                            print(r*r)\n",
    "                            Correlation.append({'time': timepoint, 'location':location, 'model':model, 'image': bands, 'r2':r_squared,'rep':rep})\n",
    "                            rep=rep+1\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "053cb878-7a24-4d0c-b2b4-c67ab9c8e73d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>location</th>\n",
       "      <th>model</th>\n",
       "      <th>image</th>\n",
       "      <th>r2</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>RF</td>\n",
       "      <td>Satellite Image</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>PSLR</td>\n",
       "      <td>Satellite Image</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>LR</td>\n",
       "      <td>Satellite Image</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>LASSO</td>\n",
       "      <td>Satellite Image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Satellite Image</td>\n",
       "      <td>0.042916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>PLSR</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.247943</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>LR</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.219688</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>LASSO</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.341655</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>SVM</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.212138</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>GB</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time     location  model            image        r2  rep\n",
       "0     TP1  Scottsbluff     RF  Satellite Image  0.027042    1\n",
       "1     TP1  Scottsbluff   PSLR  Satellite Image  0.000342    1\n",
       "2     TP1  Scottsbluff     LR  Satellite Image  0.084399    1\n",
       "3     TP1  Scottsbluff  LASSO  Satellite Image       NaN    1\n",
       "4     TP1  Scottsbluff    SVM  Satellite Image  0.042916    1\n",
       "...   ...          ...    ...              ...       ...  ...\n",
       "1345  TP1         Ames   PLSR              UAV  0.247943    5\n",
       "1346  TP1         Ames     LR              UAV  0.219688    5\n",
       "1347  TP1         Ames  LASSO              UAV  0.341655    5\n",
       "1348  TP1         Ames    SVM              UAV  0.212138    5\n",
       "1349  TP1         Ames     GB              UAV  0.133558    5\n",
       "\n",
       "[1350 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findcorr=pd.DataFrame(Correlation)\n",
    "findcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8aee9e73-3dd1-4777-86fa-1e6ab3eb7d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "findcorr=pd.DataFrame(Correlation)\n",
    "findcorr.to_excel('Figure3/FinalCorrelation_newversion.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb007760-d651-489f-b65c-8d0f0992dc32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dates=pd.read_excel('Figure1/Figure1A/DateofCollection.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3c73066-9251-4444-8eff-3f34884db024",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Image</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>2022-07-04</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>2022-07-17</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>2022-08-07</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>2022-08-18</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>2022-07-08</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>2022-07-22</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>2022-08-12</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>North Platte</td>\n",
       "      <td>2022-07-09</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>North Platte</td>\n",
       "      <td>2022-07-17</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>North Platte</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>North Platte</td>\n",
       "      <td>2022-08-22</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>North Platte</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>North Platte</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>North Platte</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>North Platte</td>\n",
       "      <td>2022-07-19</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>North Platte</td>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2022-07-18</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2022-09-03</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Lincoln</td>\n",
       "      <td>2022-08-04</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Missouri Valley</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Missouri Valley</td>\n",
       "      <td>2022-07-21</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Missouri Valley</td>\n",
       "      <td>2022-08-08</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Missouri Valley</td>\n",
       "      <td>2022-09-03</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Missouri Valley</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Missouri Valley</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Missouri Valley</td>\n",
       "      <td>2022-07-13</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Missouri Valley</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Missouri Valley</td>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ames</td>\n",
       "      <td>2022-07-15</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ames</td>\n",
       "      <td>2022-07-23</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Ames</td>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ames</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ames</td>\n",
       "      <td>2022-09-11</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ames</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Ames</td>\n",
       "      <td>2022-07-12</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ames</td>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Ames</td>\n",
       "      <td>2022-08-10</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Crawfordsville</td>\n",
       "      <td>2022-07-10</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Crawfordsville</td>\n",
       "      <td>2022-07-20</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Crawfordsville</td>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Crawfordsville</td>\n",
       "      <td>2022-09-13</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Crawfordsville</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Crawfordsville</td>\n",
       "      <td>2022-10-09</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>TP6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Crawfordsville</td>\n",
       "      <td>2022-07-12</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Crawfordsville</td>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Crawfordsville</td>\n",
       "      <td>2022-08-11</td>\n",
       "      <td>UAV</td>\n",
       "      <td>TP3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Location       Date      Image time\n",
       "0       Scottsbluff 2022-07-04  Satellite  TP1\n",
       "1       Scottsbluff 2022-07-17  Satellite  TP2\n",
       "2       Scottsbluff 2022-08-07  Satellite  TP3\n",
       "3       Scottsbluff 2022-08-18  Satellite  TP4\n",
       "4       Scottsbluff 2022-09-09  Satellite  TP5\n",
       "5       Scottsbluff 2022-09-24  Satellite  TP6\n",
       "6       Scottsbluff 2022-07-08        UAV  TP1\n",
       "7       Scottsbluff 2022-07-22        UAV  TP2\n",
       "8       Scottsbluff 2022-08-12        UAV  TP3\n",
       "9      North Platte 2022-07-09  Satellite  TP1\n",
       "10     North Platte 2022-07-17  Satellite  TP2\n",
       "11     North Platte 2022-08-04  Satellite  TP3\n",
       "12     North Platte 2022-08-22  Satellite  TP4\n",
       "13     North Platte 2022-09-02  Satellite  TP5\n",
       "14     North Platte 2022-09-25  Satellite  TP6\n",
       "15     North Platte 2022-07-13        UAV  TP1\n",
       "16     North Platte 2022-07-19        UAV  TP2\n",
       "17     North Platte 2022-08-03        UAV  TP3\n",
       "18          Lincoln 2022-07-18  Satellite  TP1\n",
       "19          Lincoln 2022-08-06  Satellite  TP2\n",
       "20          Lincoln 2022-09-03  Satellite  TP3\n",
       "21          Lincoln 2022-09-11  Satellite  TP4\n",
       "22          Lincoln 2022-09-19  Satellite  TP5\n",
       "23          Lincoln 2022-09-27  Satellite  TP6\n",
       "24          Lincoln 2022-07-13        UAV  TP1\n",
       "25          Lincoln 2022-07-28        UAV  TP2\n",
       "26          Lincoln 2022-08-04        UAV  TP3\n",
       "27  Missouri Valley 2022-07-13  Satellite  TP1\n",
       "28  Missouri Valley 2022-07-21  Satellite  TP2\n",
       "29  Missouri Valley 2022-08-08  Satellite  TP3\n",
       "30  Missouri Valley 2022-09-03  Satellite  TP4\n",
       "31  Missouri Valley 2022-09-11  Satellite  TP5\n",
       "32  Missouri Valley 2022-09-19  Satellite  TP6\n",
       "33  Missouri Valley 2022-07-13        UAV  TP1\n",
       "34  Missouri Valley 2022-07-27        UAV  TP2\n",
       "35  Missouri Valley 2022-08-10        UAV  TP3\n",
       "36             Ames 2022-07-15  Satellite  TP1\n",
       "37             Ames 2022-07-23  Satellite  TP2\n",
       "38             Ames 2022-08-10  Satellite  TP3\n",
       "39             Ames 2022-08-31  Satellite  TP4\n",
       "40             Ames 2022-09-11  Satellite  TP5\n",
       "41             Ames 2022-09-24  Satellite  TP6\n",
       "42             Ames 2022-07-12        UAV  TP1\n",
       "43             Ames 2022-07-26        UAV  TP2\n",
       "44             Ames 2022-08-10        UAV  TP3\n",
       "45   Crawfordsville 2022-07-10  Satellite  TP1\n",
       "46   Crawfordsville 2022-07-20  Satellite  TP2\n",
       "47   Crawfordsville 2022-08-02  Satellite  TP3\n",
       "48   Crawfordsville 2022-09-13  Satellite  TP4\n",
       "49   Crawfordsville 2022-10-01  Satellite  TP5\n",
       "50   Crawfordsville 2022-10-09  Satellite  TP6\n",
       "51   Crawfordsville 2022-07-12        UAV  TP1\n",
       "52   Crawfordsville 2022-07-26        UAV  TP2\n",
       "53   Crawfordsville 2022-08-11        UAV  TP3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "844c20e0-bd4d-4798-8eb0-992798dd700f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "findcorr['image']=findcorr['image'].replace({'Satellite Image': 'Satellite'})\n",
    "findcorr['location']=findcorr['location'].replace({'Movalley':'Missouri Valley','Crawfordsville':'Crawfordsville'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1066948c-4929-4d34-aab0-b21c37cda9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>location</th>\n",
       "      <th>model</th>\n",
       "      <th>image</th>\n",
       "      <th>r2</th>\n",
       "      <th>rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>RF</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>PSLR</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>LR</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>0.084399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>LASSO</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Scottsbluff</td>\n",
       "      <td>SVM</td>\n",
       "      <td>Satellite</td>\n",
       "      <td>0.042916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>PLSR</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.247943</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>LR</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.219688</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>LASSO</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.341655</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>SVM</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.212138</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>TP1</td>\n",
       "      <td>Ames</td>\n",
       "      <td>GB</td>\n",
       "      <td>UAV</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time     location  model      image        r2  rep\n",
       "0     TP1  Scottsbluff     RF  Satellite  0.027042    1\n",
       "1     TP1  Scottsbluff   PSLR  Satellite  0.000342    1\n",
       "2     TP1  Scottsbluff     LR  Satellite  0.084399    1\n",
       "3     TP1  Scottsbluff  LASSO  Satellite       NaN    1\n",
       "4     TP1  Scottsbluff    SVM  Satellite  0.042916    1\n",
       "...   ...          ...    ...        ...       ...  ...\n",
       "1345  TP1         Ames   PLSR        UAV  0.247943    5\n",
       "1346  TP1         Ames     LR        UAV  0.219688    5\n",
       "1347  TP1         Ames  LASSO        UAV  0.341655    5\n",
       "1348  TP1         Ames    SVM        UAV  0.212138    5\n",
       "1349  TP1         Ames     GB        UAV  0.133558    5\n",
       "\n",
       "[1350 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findcorr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa52d131-c601-47e3-a1b3-73aa26262015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial=pd.merge(findcorr, dates,left_on=['time','location', 'image'], right_on=['time','Location','Image'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "902e1f9a-1132-44cc-82a4-5006664be139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial['Date'] = pd.to_datetime(trial['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8f1a8ce-b5cd-4d80-85ad-21afd6778ade",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location\n",
       "Scottsbluff        9\n",
       "North Platte       9\n",
       "Lincoln            9\n",
       "Missouri Valley    9\n",
       "Ames               9\n",
       "Crawfordsville     9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c95c72a7-0690-49c4-b26a-a7710a8ff671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "Scottsbluff        270\n",
       "Crawfordsville     270\n",
       "Lincoln            270\n",
       "Missouri Valley    270\n",
       "Ames               270\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d893201-934f-43ff-8c4c-483f0aa778c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trial.to_excel('Figure3/FinalCorrelationDates.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a9f63-5831-47f0-a5dc-c6c848e3f5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
